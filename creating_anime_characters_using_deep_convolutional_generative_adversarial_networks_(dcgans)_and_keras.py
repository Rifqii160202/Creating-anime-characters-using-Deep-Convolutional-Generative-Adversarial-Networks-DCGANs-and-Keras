# -*- coding: utf-8 -*-
"""Creating anime characters using Deep Convolutional Generative Adversarial Networks (DCGANs) and Keras.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N7fxgEB6TVY1q-zw2_ZF_PaEt3tICFF_
"""

!pip install tensorflow matplotlib numpy pillow

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam

from google.colab import drive
drive.mount('/content/drive')

# Path ke dataset
data_dir = '/content/drive/MyDrive/path_to_dataset'

def build_generator(latent_dim):
    model = models.Sequential([
        layers.Dense(4 * 4 * 256, input_dim=latent_dim),
        layers.Reshape((4, 4, 256)),
        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", activation="relu"),
        layers.BatchNormalization(),
        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding="same", activation="relu"),
        layers.BatchNormalization(),
        layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding="same", activation="relu"),
        layers.BatchNormalization(),
        layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding="same", activation="tanh")
    ])
    return model

def build_discriminator(img_shape):
    model = models.Sequential([
        layers.Conv2D(64, kernel_size=4, strides=2, padding="same", input_shape=img_shape),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(128, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(256, kernel_size=4, strides=2, padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Flatten(),
        layers.Dense(1, activation="sigmoid")
    ])
    return model

img_shape = (64, 64, 3)
discriminator = build_discriminator(img_shape)

"""# Bagian Baru"""

def build_gan(generator, discriminator):
    # Discriminator tidak dilatih selama pelatihan GAN
    discriminator.trainable = False

    # Input untuk GAN
    gan_input = layers.Input(shape=(latent_dim,))

    # Generator menghasilkan gambar dari input noise
    generated_image = generator(gan_input)

    # Discriminator mengevaluasi gambar yang dihasilkan
    gan_output = discriminator(generated_image)

    # Kombinasikan Generator dan Discriminator
    gan = models.Model(gan_input, gan_output)
    gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')
    return gan

    # Pastikan `generator` dan `discriminator` sudah dibuat sebelumnya
    gan = build_gan(generator, discriminator)
    gan.summary()

from PIL import Image  # Impor dengan benar

def preprocess_images(data_dir, img_size=(64, 64)):
    images = []
    for img_name in os.listdir(data_dir):
        img_path = os.path.join(data_dir, img_name)
        img = Image.open(img_path).resize(img_size).convert("RGB")  # Gunakan Image.open
        images.append(np.asarray(img) / 127.5 - 1)  # Normalize to [-1, 1]
    return np.array(images)

# Contoh pemanggilan fungsi
anime_images = preprocess_images(data_dir)
print(f"Dataset size: {anime_images.shape}")

latent_dim = 100
generator = build_generator(latent_dim)

# Generate a sample image
noise = np.random.normal(0, 1, (1, latent_dim))
generated_image = generator.predict(noise)
print(f"Generated image shape: {generated_image.shape}")

def train_dcgan(generator, discriminator, gan, images, latent_dim, epochs, batch_size):
    half_batch = batch_size // 2
    for epoch in range(epochs):
        # Train Discriminator
        idx = np.random.randint(0, images.shape[0], half_batch)
        real_imgs = images[idx]
        noise = np.random.normal(0, 1, (half_batch, latent_dim))
        fake_imgs = generator.predict(noise)
        d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((half_batch, 1)))
        d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((half_batch, 1)))
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train Generator
        noise = np.random.normal(0, 1, (batch_size, latent_dim))
        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))

        # Display progress
        if epoch % 100 == 0:
            print(f"Epoch: {epoch}/{epochs} | D Loss: {d_loss[0]} | G Loss: {g_loss}")
            save_generated_images(generator, latent_dim, epoch)

def save_generated_images(generator, latent_dim, epoch, examples=25, dim=(5, 5), figsize=(10, 10)):
    noise = np.random.normal(0, 1, (examples, latent_dim))
    generated_images = generator.predict(noise)
    generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1] for visualization
    fig, axs = plt.subplots(dim[0], dim[1], figsize=figsize)
    cnt = 0
    for i in range(dim[0]):
        for j in range(dim[1]):
            axs[i, j].imshow(generated_images[cnt])
            axs[i, j].axis('off')
            cnt += 1
    plt.savefig(f"generated_images_epoch_{epoch}.png")
    plt.close()

latent_dim = 100
img_shape = (64, 64, 3)

generator = build_generator(latent_dim)
discriminator = build_discriminator(img_shape)
gan = build_gan(generator, discriminator)

train_dcgan=(generator, discriminator, gan, anime_images, latent_dim, epochs, batch_size)

from PIL import Image
import numpy as np

generated_image = np.random.rand(64, 64, 3) * 255  # Contoh gambar acak
generated_image = generated_image.astype(np.uint8)  # Ubah ke tipe data uint8

pil_image = Image.fromarray(generated_image)

epoch = 100
pil_image.save(f'generated_images_epoch_{epoch}.png')

from PIL import Image
from IPython.display import display
import os

directory = '/content/drive/MyDrive/path_to_dataset'

files = os.listdir(directory)
print(files)  # Lihat daftar file di direktori

image_filename = '993_2000.jpg'
img_path = os.path.join(directory, image_filename)

img = Image.open(img_path)
display(img)